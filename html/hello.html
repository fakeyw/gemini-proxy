<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Welcome to the LLM API Proxy!</title>
        <style>
            body { font-family: sans-serif; line-height: 1.6; padding: 2em; background-color: #f4f4f4; color: #333; }
            .container { max-width: 800px; margin: auto; background: #fff; padding: 2em; border-radius: 8px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }
            h1 { color: #007bff; }
            code { background-color: #eee; padding: 0.2em 0.4em; border-radius: 3px; }
        </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ‘‹ Welcome to Cloudflare Worker LLM API Proxy!</h1>
        <p>This worker acts as a proxy for your configured LLM API (<code>${UPSTREAM_API_URL}</code>).</p>
            <p>It intelligently manages multiple API keys:</p>
        <ul>
            <li>Rotates available API keys provided via the <code>API_KEYS</code> secret.</li>
            <li>Automatically marks keys as exhausted if the upstream API returns a 429 status code.</li>
            <li>Resets the status of all keys daily at GMT+8 15:00 (UTC 07:00) via a scheduled task.</li>
        </ul>
        <p>To use the proxy, simply send your API requests to this worker's URL instead of directly to the LLM API URL.</p>
        <hr>
        <p><small>You are seeing this page because you visited the <code>/</code> endpoint.</small></p>
    </div>
</body>
</html>